\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage{multirow,array}
\usepackage{graphicx}
\usepackage{a4wide}
\newcommand{\HRule}{\rule{\linewidth}{1mm}}

\begin{document}


%
%  TITRE
%

\begin{titlepage}

\begin{center}
\huge Une aide à la programmation sur GPU\\ pour le calcul scientifique
\HRule \\
\medskip
{\Huge \bfseries La librairie GMlib} \\
\HRule
\end{center}

\vspace*{\stretch{3}}

\begin{figure}[htbp]
\begin{center}
\includegraphics[height=10cm]{gpu.pdf}
\end{center}
\end{figure}

\vspace*{\stretch{1}}

\begin{flushright}
\Large Lo\"ic MAR\'ECHAL / INRIA, Projet Gamma\\
\Large Avril 2020 \\
\normalsize Document v2.02
\normalsize Librairie v3.19
\end{flushright}

\end{titlepage}

\clearpage

\setcounter{tocdepth}{2}
\tableofcontents
\vfill

\footnotesize{Couverture : différentes cartes graphiques ou accélératrices capables d'exécuter du code OpenCL.}
\normalsize

\clearpage


%
%  1 / INTRODUCTION
%

\section{Introduction}
La {\tt GMlib} v3 est une librairie visant à grandement faciliter le portage ou développement de logiciels de calculs scientifiques utilisant des maillages non structurés comme principale donnée.

Elle est basée sur le standard ouvert OpenCL, qui a pour avantage de fonctionner sur la plupart des matériels et systèmes actuels.
OpenCL tire non seulement parti des GPU des trois principaux constructeurs, AMD, Intel et Nvidia, mais aussi des GPU intégrés des smartphones et tablettes (ARM, Imagination Technologies, etc.).
Et en l'absence de GPU dans un appareil, il est parfaitement à même d'utiliser efficacement tous les coeurs et capacités vectorielles des CPU, ce qui en fait une technologie très générique.

Mais le développement d'applications performantes et industrielles, c'est à dire, autre chose que la résolution d'un laplacien sur une grille structurée et carrée, requiert un investissement et des compétences conséquentes de la part des programmeurs.
Il est très important de noter qu'en matière de code sur GPU, c'est le stockage, transfert et accès efficace aux données qui sont le plus problématiques et non les algorithmes, qui ne nécessitent pas tant d'adaptation par rapport aux plateformes CPU parallèles conventionnelles.

C'est pourquoi l'idée sous-jacente de la {\tt GMlib} est d'abstraire autant que possible la gestion des données et de laisser le programmeur le plus libre possible sur la partie code proprement dite.
Les GPU étant à l'origine conçus pour l'affichage graphique, il est naturel d'en utiliser le paradigme de programmation proposé par les principaux acteurs : les shaders.

L'approche du graphisme sur GPU consiste à demander au programmeur de transmettre l'ensemble des données nécessaires à l'affichage à la librairie (OpenGL, Direct 3D), puis de fournir un code assez succins, appelé shader, à appliquer sur chaque entité graphique sélectionnée.
Il est par exemple courant de fournir un ensemble de sommets, de triangles, de vecteurs normaux aux sommets, et par la suite, de demander à la librairie graphique de boucler sur les triangles tout en accédant aux coordonnées et normales de leurs sommets afin d'exécuter un code (shader) calculant la couleur et la position à l'écran de chaque pixel du triangle.

Une telle approche a été reprise pour la {\tt GMlib}, mais ici les textures, projections, et effets graphiques sont remplacés par des tétraèdres, arrêtes, champs de solutions physiques, et tous les accès indirects possibles entre ces entités.
Les types de données de maillage actuellement proposées sont : sommets, arrêtes, triangles, quadrilatères, tétraèdres, pyramides, prismes et hexaèdres ainsi que les liens implicitent qui les relient entre eux (boules, coquille, voisin) et qui sont automatiquement construits par la librairie.
De plus, des types de données libres (entier, flottant, scalaires, tableaux, vecteur) peuvent être associés à chaque entité de maillage afin d'y stocker les données nécessaires aux calculs.

Un code basé sur la {\tt GMlib} se décompose en quatre étapes : initialisations, renseignements des données, compilation des kernels et exécution de ces derniers sur GPU.

Initialisation :
On doit tout d'abord initialiser la librairie en lui fournissant le numéro du matériel qui va exécuter le kernel en OpenCL.
Puis on dimensionne chaque type de donnée de maillage et de solution associée simplement en fournissant le nombre de chaque entité et la taille des données, c'est une phase de description des données.

Renseignement des données :
L'utilisateur doit boucler sur chaque sommet, élément, ou autre donné précédemment déclarés pour en transmettre le contenue à la {\tt GMlib}, qui elle-même se chargera de les transmettre sur la carte graphique au moment et sous la forme adéquate.

Compilation des kernels :
L'utilisateur décrit les boucles qu'il souhaite exécuter sur GPU en précisant pour chacune, la liste des entités de maillage et solutions qui lui seront nécessaires, ainsi que leur mode d'accès, lecture et/ou écriture, puis le code source du code à exécuter sur ces données et qui sera au préalable compilé par la librairie.
Cette compilation à chaud, permet de générer un code binaire exécutable au moment même de l'exécution du logiciel, ce qui lui permet de fonctionner sur l'importe quel type de matériel (AMD, Intel, NVIDIA, etc.)

Exécution des kernels :
Une fois toutes les données définies et transmises et les codes compilés et optimisés sur l'architecture choisie, il ne reste plus qu'a lancer l'exécution de chaque kernel, autant de fois que nécessaire pour converger un calcul et en ne modifiant que quelques paramètres globaux afin de contrôler ledit calcul (coefficients, résidus, flags, etc.)

\subsection{Motivation}
Les deux principales motivations à la programmation sur GPU sont leur rapport performance/prix, bien plus intéressant que celui des CPU standards, ainsi que leur capacité d'évolution future, elle aussi bien plus grande que celle des CPU multic\oe urs qui semble être limitée à moyen terme.

Il faut néanmoins être réaliste, le prix d'une carte graphique haut de gamme est très élevé et souvent assez proche de celui d'un serveur de calcul. Quant aux performances annoncées par les constructeurs ou publiées dans de nombreux articles scientifiques surfant sur l'effet de mode des GPU, ils ne sont que théoriques. De nombreux codes d'exemples servant à démontrer la puissance des GPU n'utilisent que des algorithmes et des données simplifiées non représentatifs de la réalité industrielle de la simulation numérique. De plus, ils recourent à l'astuce de comparer un code sur GPU avec son équivalent séquentiel sur CPU... Les serveurs actuels possédant 12 ou 16 c\oe urs, la comparaison GPU / CPU multic\oe urs est nettement moins favorable.

Dans la pratique, le portage d'un code industriel travaillant sur des données réelles sur GPU ne saurait être plus de deux à quatre fois plus rapide qu'un bon serveur de calcul multi-c\oe urs. Ceci est déjà intéressant non seulement d'un point de vue prix, mais aussi d'encombrement (une carte d'extension contre plusieurs unités de racks) ou de consommation électrique.

Le gain espéré n'étant pas si extraordinaire, il est donc important pour un développeur de ne pas investir trop de temps dans une tentative de portage. Et c'est justement le problème de la programmation sur GPU : elle est très fastidieuse et consommatrice de temps !

Deux postes sont notamment lourds : la mise en forme et le transfert des structures de données de et vers le GPU, telles qu'elles soient assimilables et efficaces pour celui-ci, et le portage, l'optimisation et le débogage des algorithmes proprement dits dans le langage du GPU.
Il a donc paru important de proposer aux développeurs une librairie simplifiant ces deux aspects dans le cadre d'applications traitant des maillages, données de base de la plupart des codes de simulations numériques. La librairie proposée, la {\tt GMlib}, fourni donc au développeur des structures de données de maillages simples à définir et transférer ainsi qu'une panoplie de codes sources de base en OpenCL permettant d'y accéder efficacement.

Le mode opératoire est donc le suivant :

-choisir les types de données parmi ceux proposés qui vous permettront de stocker vos données,
-partir d'un des codes de base proposés accédant à ce type de données et y insérer vos propres calculs sur ces données.

Ceci nous amène donc à parler de l'interfaçage entre vos données et la librairie, autrement dit, l'API.

\subsection{API}

L'interaction avec la librairie repose sur deux éléments fondamentaux : les types de données et les codes (i.e. kernels) qui vont opérer sur celles-ci.
Logiquement, le déroulement d'un logiciel utilisant un accélérateur GPU va se dérouler en deux phases :

\begin{itemize}
\item l'allocation et la définition des données (maillages, champs de solutions, liens topologiques),
\item la déclaration, la compilation et l'exécution des kernels en OpenCL
\end{itemize}

Toutes ces phases sont exécutées par le CPU hôte et seule les kernels tournent sur GPU et s'en trouveront donc accélérées.
Dire d'un code qu'il "tourne sur GPU" est abus de langage, car les entrées-sorties, initialisation, compilation et post-traitement sont exécutés sur CPU et l'on doit parler de logiciel hybride CPU/GPU.
Il est donc important d'optimiser toutes les phases d'initialisation, car celle-ci représente le \emph{coefficient d'Amdahl} de tout code hybride CPU/GPU.

L'interfaçage avec la {\tt Gmlib} commence donc par son initialisation en lui fournissant le numéro du périphérique de calcul sur lequel les kernels seront exécutés : {\tt LibIdx = GmlInit(2);}

Sur la machine de l'auteur de ces lignes, une telle commande initialise la librairie avec la carte graphique \emph{ATI Radeon Pro 460} et l'étiquette retournée servira à communiquer avec toutes les autres commandes de la librairie par la suite.
Notez que plusieurs instances de la librairie peuvent être ouvertes simultanément, avec le même périphérique, ou bien un autre.

Remarque : une instance ne peut utiliser qu'un seul périphérique de calcul, composé lui-même de plusieurs \emph{compute units} et une seule zone mémoire, il s'agit donc de parallélisme à mémoire partagée.

Si l'utilisateur souhaite combiner la puissance de plusieurs GPU, il devra implémenter la distribution des calculs entre les cartes lui-même.

Ensuite il faut définir et renseigner les types de données qui seront utilisés par les calculs effectués sur le GPU.
Cela introduit un aspect très important : l'utilisateur ne peut utiliser ses propres données en mémoire CPU (tableaux, structures, objets, etc.), mais doit obligatoirement les déclarer et le transférer à la librairie. C'est une contrainte très forte, car la nature des données offertes est assez limitée et le portage d'un code sur GPU va surtout consister à plier ses propres structures de données dans le canevas proposé par la {\tt GMlib}.

Pour illustrer les processus, on va déclarer et renseigner les sommets d'un maillage que l'on vient de lire et de ranger dans le tableau {\tt crd[n][3]} et assigner à chacun une vitesse et un vecteur de déplacement aléatoire.

\begin{tt}
\begin{verbatim}
VerIdx = GmlNewMeshData(LibIdx, GmlVertices, NmbVer);
for(i=0;i<NmbVer;i++)
   GmlSetDataLine(LibIdx, VerIdx, i, crd[i][0], crd[i][1], crd[i][2], 0);

VitIdx = GmlNewSolutionData(LibIdx, GmlVertices, 1, GmlFlt, "Vitesse");
for(i=0;i<NmbVer;i++)
{
   vitesse = rand();
   GmlSetDataLine(LibIdx, MasIdx, i, &vitesse);
}

DirIdx = GmlNewSolutionData(LibIdx, GmlVertices, 1, GmlFlt4, "Direction");
for(i=0;i<NmbVer;i++)
{
   vecteur[0] = rand();
   vecteur[1] = rand();
   vecteur[2] = rand();
   vecteur[3] = 0;
   GmlSetDataLine(LibIdx, MasIdx, i, &vecteur);
}
\end{verbatim}
\end{tt}
\normalfont

On souhaite calculer sur GPU le déplacement itératif de ces sommets selon leur direction et vitesse et récupérer les coordonnées résultantes après 1000 itérations.

Pour cela, nous allons tout d'abord écrire le code de déplacement d'une itération en OpenCL : il s'agit d'un kernel et il doit être placé dans un fichier indépendant, que nous appellerons iteration.cl.
Puis on va le compiler en lui passant les données préalablement définies : les sommets qu'on souhaite envoyer sur le GPU et récupérer à la fin (\emph{Read \& Write}) et la vitesse et le déplacement qu'on souhaite envoyer, mais pas récupérer (\emph{Read}).

\begin{tt}
\begin{verbatim}
KrnIdx = GmlCompileKernel( LibIdx,  iteration, "iteration", GmlVertices, 3,
                           VerIdx, GmlReadMode | GmlWriteMode, NULL,
                           VitIdx, GmlReadMode               , NULL,
                           DirIdx, GmlReadMode               , NULL );
\end{verbatim}
\end{tt}
\normalfont

Et voici le fameux kernel nommé \emph{iteration.cl} : 

\begin{tt}
\begin{verbatim}
VerCrd = VerCrd + VerVitesse * VerDirection;
\end{verbatim}
\end{tt}
\normalfont

Ce code, on ne peux plus succin, amène de nombreuses remarques :

\begin{itemize}
\item il n'y a pas de boucle itérant de 1 à NmbVer,
\item il ne comporte aucune définition préalable des variables utilisée,
\item il n'y a pas d'accès aux tableaux des sommets et données associées, mais seulement des scalaires,
\item comment sera stocké le résultat,
\item les coordonnées et le champ de déplacement sont des vecteurs en 3-D.
\end{itemize}

\paragraph{Boucle implicite : } il y a bien un compteur de boucle qui est incrémenté de 1 à NmbVer, mais la boucle est effectué par le GPU et l'utilisateur n'a pas moyen de contrôler l'ordre de traitement des sommets. Il ne fournit que le noyau de la boucle (d'où le nom kernel), sans itérateur, et ce morceau de code sera instancié et exécuté autant de fois qu'il y a de sommets dans le maillage, mais dans un ordre non spécifié !

\paragraph{Variables implicites : } les déclarations de variables locales sont effectuées par la librairie en fonction des paramètres définis lors de la compilation du kernel.
Nous avions demandé l'accès aux coordonnées des sommets (un vecteur 3-D), à la vitesse (scalaire) et au vecteur de déplacement (vecteur 3-D) et la librairie a donc défini d'elle-même les variables du type adéquat pour recevoir toutes les données demandées de l'unique sommet en cours de traitement. Les noms des données de type maillage sont imposés par la librairie et connus (VerCrd pour les coordonnées, TriVer pour les numéros des trois sommets d'un triangle), quant aux données librement définies par l'utilisateur, elles portent le nom qu'il leur a assigné au moment de l'initialisation.
Dans notre exemple, {\tt vitesse} est un scalaire et {\tt direction} est un vecteur.
Le code des définitions est en fait créé par la librairie et ajouté juste avant le kernel fourni par l'utilisateur.

\paragraph{Accès aux tableaux globaux : } il n'y a pas qu'un seul sommet dans le maillage et pourtant la librairie n'a défini qu'un seul vecteur {\tt VerCrd} contentant les coordonnées d'un seul sommet. Là encore, la librairie a bien défini le tableau des coordonnées ({\tt VerCrdTab[ NmbVer ]}), mais celui-ci est caché à l'utilisateur et les coordonnées du sommet en cours de traitement sont automatiquement lues avant de passer la main au kernel.
De fait, lorsque l'unique ligne du kernel d'exemple commence à être exécutée, la librairie a déjà fait remplir les variables locales avec les données du sommet courant \emph{i} : {\tt VerCrd = VerCrdTab[i]}, {\tt vitesse = vitesseTab[i]}, {\tt direction = directionTab[i]} et il n'a pas à se soucier du transfert des variables globales vers les locales sur lesquelles il va effectuer les calculs.

\paragraph{Stockage du résultat en mémoire : } de la même manière qu'avec les lectures, toutes les variables étant définie comme \emph{Write} au moment de la compilation, seront stockées dans les tableaux globaux après l'exécution du kernel utilisateur. Cette écriture est cachée et transparente. Dans l'exemple, seules les coordonnées sont accédées en écriture et la librairie rajoutera d'elle-même la ligne suivante : {\tt VerCrdTab[i] = VerCrd} afin de stocker le résultat du calcul sur ce sommet dans la mémoire du GPU, d'éventuels calculs intermédiaires étant perdus !

\paragraph{Calcul vectoriel : } le langage OpenCL offre des variantes scalaires et vectorielles de tailles 2,4,8 ou 16 pour chaque type de données entières (8,16,32 ou 64 bits) et réelles (16,32 ou 64 bits) et utilise la technique du surtypage d'opérateur pour adapter des opérations aux types des opérandes. Dans notre kernel, {\tt VerCrd} et {\tt direction} sont des vecteurs 3-D et effectuer l'opération {\tt VerCrd = VerCrd + direction} va déclencher une addition vectorielle traitant les trois coordonnées simultanément.
Que se passe-t-il alors lorsqu'on multiplie le déplacement par le scalaire contenant la vitesse ?
Le compilateur détecte la différence de type et choisit l'opération appropriée, dans le cas présent, il va utiliser la fonction multipliant tous les termes d'un vecteur par un scalaire.


\subsection{Les types de données}

L'utilisateur étant contraint à utiliser uniquement les types de données proposés, il est donc très important de bien en comprendre le fonctionnement et tous les usages possibles.
Les types se regroupent en trois catégories : les données des maillages (sommets, arêtes, triangles, etc.), les champs de solutions libres (des tableaux, scalaires ou vecteurs associés à chaque entité d'un type de maillage) et enfin les liens topologiques, de loin les plus complexes, qui permettent des accès indirects efficaces entres différents types (boules des points, voisinages par face, coquille d'arêtes).

\paragraph{Types de données de maillage :} elles permettent de représenter tout maillage hybride à l'ordre un, les ordres deux et trois étant prévus pour une version ultérieure. Sont donc proposés les types classiques, Vertices, Edges, Triangles, Quadrilaterals, Tetrahedra, Pyramids, Prisms et Hexahedra. Les sommets (Vertices) sont composés de trois flottants et d'un entier pour stocker les coordonnées et la référence physique, et tous les éléments sont composés de 2 à 8 entiers pour stocker les numéros de sommets ainsi qu'un entier supplémentaire pur la référence.
Remarque : tous les indices de tableaux vont de 0 à n-1.
Leur allocation se fait avec la commande {\tt GmlNewMeshData}, en spécifiant simplement le nombre d'entités souhaitées dans le maillage. Notez qu'une instance de la librairie ne peut comporter qu'un seul tableau d'un même type de maillage, il n'est donc pas possible d'allouer deux tableaux de triangles par exemple.
Leur renseignement se fait ensuite avec la commande {\tt GmlSetDataLine}, en précisant le type de la donnée, le numéro de l'entité (de 0 à n-1), puis un nombre variable d'arguments correspondant au sommet de l'élément en question.
L'exemple suivant alloue et renseigne trois sommets :

\begin{tt}
\begin{verbatim}
VerIdx = GmlNewMeshData(LibIdx, GmlVertices, 3);
GmlSetDataLine(LibIdx, VerIdx, 0, 1.5, 2.3, 1.0, 8);
GmlSetDataLine(LibIdx, VerIdx, 1, 9.2, 8.3, 1.0, 6);
GmlSetDataLine(LibIdx, VerIdx, 2, 6.3, 1.6, 2.3, 0);
\end{verbatim}
\end{tt}
\normalfont

\paragraph{Les champs associés : } ils permettent d'associer des données librement à toutes les entités d'un type de maillage donné. Il ne peut y avoir qu'un seul type de donnée OpenCL dans un champ, mais ce type peut être vectoriel (taille de 2 à 16) et peut même être composé d'un tableau de vecteur.
Les types scalaires proposés sont : byte, int, float et double ainsi que leurs déclinaisons vectorielles.
Chaque type de solution est associé à un type de maillage précis, mais il est possible de déclarer autant de champs associés pour chaque type de donnée de maillage ce qui permet de simuler l’équivalent d'une structure hybride, chaque champ stockant un type OpenCL différent.
L'allocation se fait avec la commande {\tt GmlNewSolutionData}, en spécifiant le type de maillage auquel ce champ de solution est associé, la taille du tableau local associé à une entité de maillage (= 1 pour un scalaire), ainsi que le type de la donnée (GmlByte, GmlInt16, GmlFloat4, etc.) et le nom sous lequel apparaitra la variable déclarée automatiquement.
Les données sont renseignées avec la commande {\tt GmlSetDataLine}, mais dans ce cas, on ne passe pas toutes les valeurs des champs explicitement, mais seulement un pointeur sur un tableau contenant la totalité du champ associé à cette entité et qui sera recopié dans la structure interne de la librairie.
L'exemple suivant alloue et renseigne un tableau de deux flottants pour chacun des trois sommets alloués précédemment :

\begin{tt}
\begin{verbatim}
float vec[2];
VecIdx = GmlNewSolutionData(LibIdx, GmlVertices, 2, GmlFlt, "masse_vitesse");
vec = {1.2, -6.3};
GmlSetDataLine(LibIdx, VecIdx, 0, &vec);
vec = {0.3,  5.2};
GmlSetDataLine(LibIdx, VecIdx, 1, &vec);
vec = {3.4, -0.1};
GmlSetDataLine(LibIdx, VecIdx, 2, &vec);
\end{verbatim}
\end{tt}
\normalfont

\paragraph{Les liens topologiques : } c'est l'entité la plus complexe à appréhender et manipuler, mais aussi la plus puissante, grâce à elle, et un peu d'imagination, on peut contourner l'essentiel des limitations imposées par le calcul GPU.
Un lien topologique permet de lier un type de maillage source et un type de destination, par exemple lier les triangles vers les tétraèdres, ce qui consiste à fournir les indices des deux tétraèdres pour chaque triangle. Un tel tableau serait associé aux triangles (la source) et serait composé de deux entiers par triangles (un maximum de deux tétraèdres peut partager un même triangle). Les liens ne sont pas commutatifs, car inverser les triangles et les tétraèdres revient à donner pour chaque tétraèdre (la source), la liste des quatre triangles qui constituent ses faces.
Ces liens topologiques vont être utilisés dans les kernels à accès mémoire indirect, voir section xxx, et permettront d'accéder aux données associées aux tétraèdres dans une boucle sur les triangles, pour reprendre notre premier exemple.
Un des points forts de la {\tt GMlib} est qu'elle va automatiquement construire les liens standards entre tous les types de données, et ce au moment de la compilation d'un kernel. Par exemple, si on demander une boucle sur les arrêtes, et que des données à lires sont associées à des triangles, la coquille des triangles pour chaque arête sera construite.
L'utilisateur ne sera amené à créer ses propres liens topologiques que pour effectuer des accès mémoires indirects spécifiques à son algorithme, par exemple, donner les deux triangles "upwind" et "downwind" pour chaque arête dans un solveur fluide. Dans un tel cas en 2-D, si l'utilisateur demandait une boucle sur les arêtes et voulait lire des données de calculs associées aux triangles, la librairie construirait le lien topologique naturel partant des arêtes pour pointer sur les triangles : il s'agirait des deux triangles partageant une même arête, et ce n'est pas ce dont le solveur a besoin !
Dans ce cas, il sera de la responsabilité de l'utilisateur d'allouer un type de donnée topologique avec la commande {\tt GmlNewLinkData} en précisant les étiquettes des types sources et destination ainsi que le nombre de liens pour chaque source, car vous pourriez avoir envie de créer une table donnant pour chaque sommet les indices des 180 pyramides les plus proches, pourquoi pas ?
L'allocation et le remplissage sont similaires aux champs associés :

\begin{tt}
\begin{verbatim}
int pyramides[ NmbVer ][ 180 ];
PyrIdx = GmlNewLinkData(LibIdx, GmlVertices, GmlPyramides, 180, "Gizeh");
for(i=0;i<NmbVer;i++)
   GmlSetDataLine(LibIdx, PyrIdx, pyramides[i]);
\end{verbatim}
\end{tt}
\normalfont

Remarque : le lien inverse de sommet vers pyramides, soit une pyramide vers ses cinq sommets, n'est rien d'autre que le tableau des éléments pyramidaux lui-même. De fait, toutes les données de maillages ne sont que des liens entre des couples type/numéro.

\subsection{Kernels a accès directs}
C'est le type de Kernel le plus simple, comme tout kernel, il ne boucle que sur les éléments d'un seul type, et n'accède en lecture ou en écriture qu'à des données relatives au type d'élément de la boucle. Si on boucle sur les sommets et accès à un champ de solution qui leur est associée, tous les tableaux sont accédé via l'indice de boucle principal, il n'y a donc aucune indirection mémoire. C'est aussi le type de Kernel le plus efficace, car il utilise à 100\% la bande passante de la mémoire du GPU étant donné que les tableaux sont lus linéairement.
Dans l'exemple introductif de la section xxx, les deux types de solutions alloués sont relatifs aux sommets et le kernel d'une ligne boucle sur les sommets et accède aux coordonnées en lecture et écriture et aux types de solutions en lecture.

\begin{tt}
\begin{verbatim}
VerCrd = VerCrd + VerVitesse * VerDirection;
\end{verbatim}
\end{tt}
\normalfont

Dans ce kernel, à chaque itération de la boucle, de 0 à NmbVer, les coordonnées, la vitesse et le vecteur de direction sont tous lus de manière cachée par libraire qui y accède via l'indice de boucle principal $i$. Dans les faits, un GPU transférant tout d'abord à mémoire par blocs (32 ou 64 entiers consécutifs) vers la cache et accédant ensuite à cette dernière, l'accès à la case {\tt vitesse[0]} va déclencher la lecture de {\tt vitesse[0..31]}, puis les accès suivants, de 1 à 31, ne couteront que le prix d'un accès au cache.

Dans cette configuration, le nommage des variables automatique est évidant, elles portent le nom court du type de maillage de la boucle principale auquel est concaténé le nom de la variable accédée. Dans notre exemple, la boucle portant sur les GmlVertices (nom court \emph{Ver}), et on accède aux coordonnées (\emph{Crd}), à la vitesse (\emph{Vitesse}) et au vecteur de direction (\emph{Direction}), ce qui donne les noms automatiques suivants : \emph{VerCrd}, \emph{VerVitesse} et \emph{VerDirection}, élémentaire !

Remarque : les accès directs aux données peuvent être fait en mode lecture, ou écriture, ou bien les deux en même temps

\subsection{Kernels a accès indirects}
C'est ici que les choses deviennent un peu plus sérieuses.
Un kernel est dit à accès indirect lorsqu'il est amené à lire des données associées à un type de maillage différent de celui de la boucle. Dans un tel cas, les accès mémoires prennent la forme {\tt a = u[v[i]]} et non plus {\tt a = u[i]} comme c'est le cas dans les accès directs. De tels accès sont nettement plus lents pour deux raisons. Tout d'abord il faut effectuer deux accès mémoire pour obtenir une seule valeur au final, le GPU lit d'abord {\tt tmp = v[i]}, puis lit {\tt a = u[ tmp ]}. Enfin et surtout, les accès successifs à {\tt a = u[ tmp ]} ne sont pas consécutifs en mémoire lorsqu'on incrémente {\tt i} car les contenus de {\tt v[i]} sont totalement inconnus au moment de la compilation et dépendent uniquement de la numérotation des éléments et sommets du maillage. Afin de limiter le problème, on recourt à deux méthodes, la renumérotation du maillage par une courn=be de Hilbert afin d'améliorer l'efficacité de la mémoire cache, ainsi qu'a la vectorisation des liens montants (boules de points, coquilles d'arêtes), par nature irréguliers (cf xxx).
Le développement de ces kernels est totalement transparent pour l'utilisateur, car la librairie va se charger de lire le tableau d'indirection, puis les données demandées. Dans le cas d'une boucle sur les triangles (Tri), si on souhaite accéder aux coordonnées des sommets (Crd), la librairie va d'elle-même définir et remplir un tableau (TriVer[3]) de trois vecteurs contenant les coordonnées des trois sommets du triangle.
à titre d'illustration, voici un code bouclant sur les triangles et calculant leur barycentre :

\begin{tt}
\begin{verbatim}
KrnIdx = GmlCompileKernel( LibIdx,  barycentre, "barycentre", GmlTriangles, 3,
                           VerIdx, GmlReadMode , NULL,
                           TriIdx, GmlReadMode , NULL,
                           BarIdx, GmlWriteMode, NULL );
\end{verbatim}
\end{tt}
\normalfont

Et voici le fameux kernel : 

\begin{tt}
\begin{verbatim}
Bar = (TriCrd[0] + TriCrd[1] + TriCrd[3]) / 3.;
\end{verbatim}
\end{tt}
\normalfont

La variable {\tt Bar} est un unique vecteur de coordonné, car il est relatif au triangle, l'élément de la boucle alors que la variable {\tt TriCrd} est un tableau de taille 3, car elle relatives aux sommets dont un triangle est composé de trois.
Comme vous pouvez le constater, il n'est nul besoin d'accéder explicitement aux numéros des trois sommets du triangle, ceci a été effectué par la librairie juste avant de passer la main au kernel de l'utilisateur. Un lien topologique est donc une structure complètement muette.
Ce qui peut être perturbant, c'est que la même commande de compilation du kernel, mais avec {\tt GmlEdges} à la place de {\tt GmlTriangles} va produire un code différent !
En effet, la variable contenant les coordonnées l'appellera alors {\tt EdgCrd[2]} et sa taille sera de deux au lieu de trois.
On parle alors de variable et de programmation contextuelle.
Une fois maitrisée ce concept, il est possible d'accéder indirectement (en lecture seulement) à n'importe quel type de données (maillage ou solution) associées à des types de maillage complètement différents du type de la boucle, car tous les cas possibles sont gérés par la {\tt GMlib}.

\paragraph{Liens topologiques descendants, transverses et montants :} un lien est descendant si le type de la boucle est de dimension strictement supérieure au type accédé indirectement (triangle vers les arêtes), transverse si les deux types sont de même dimension (triangle vers les triangles ou quadrilatères voisins) et montant si la dimension du type indirect est strictement supérieure au type de boucle (boucle sur les sommets et accès aux triangles de leurs boules).

\paragraph{Lien descendant :} ce premier type est trivial, il s'agit le plus souvent de boucler sur un élément et d'accéder aux données associées à ses sommets. Dans ce cas, la table d'indirection est la liste des noeuds composant chaque élément et la librairie n'a qu'à la transmettre telle quelle au GPU.

\paragraph{Lien transverse :} le second type, présente une petite finesse, par défaut, si on boucle sur le triangle et accède à des données relatives aux triangles, il s'agit tout simplement d'un accès direct comme vu à la section xxx. Mais il est possible de fournir un tableau de lien topologique spécifique au moment de la compilation du kernel, comme au tableau des voisins par arêtes. Dans ce cas, on va boucler sur les triangles et accéder à des données relatives au triangle en cours de traitement ainsi qu'à ses trois voisins.
Le code suivant va récupérer les barycentres des triangles calculés à l'exemple précédent afin de déterminer la distance maximum entre le centre d'un triangle et celui de ses trois voisins.

\begin{tt}
\begin{verbatim}
NgbIdx = GmlSetNeighbours(LibIdx, GmlTriangles);
DisIdx = GmlNewSolutionData(LibIdx, GmlTriangles, 1, GmlFlt, "distance");
KrnIdx = GmlCompileKernel( LibIdx,  distance, "distance", GmlTriangles, 2,
                           BarIdx, GmlReadMode , NgbIdx,
                           DisIdx, GmlWriteMode, NULL );
\end{verbatim}
\end{tt}
\normalfont

Et voici kernel correspondant :

\begin{tt}
\begin{verbatim}
float 1d, d2, d3;
d1 = fast_distance(TriBar[0], TriBar[1]);
d2 = fast_distance(TriBar[0], TriBar[2]);
d3 = fast_distance(TriBar[0], TriBar[3]);
distance = min(d1, d2);
distance = min(distance, d3);
\end{verbatim}
\end{tt}
\normalfont

Ici, le tableau {\tt TriBar[4]} est nommé de la sorte, car on boucle sur les triangles (Tri) et on accède à leurs barycentres (Bar), mais il y a quatre barycentres lus pour chaque triangle : le premier est celui du triangle pointé par l'indice de boucle et les trois suivants sont ceux de ses voisins. Ici encore, il s'agit de variables vectorielles et une seule ligne de ces calculs traite les trois composantes des coordonnées.

\paragraph{Lien montant :} enfin le dernier type est aussi le plus complexe, car les liens montants présentent l'inconvénient majeur d'être de taille variable, chose que détestent les GPU, qui ne sont efficaces qu'avec des tailles régulières et de puissance de 2. En effet, si le nombre de sommets d'un triangle est toujours égal à trois, le nombre de triangles partageant un même sommet est variable et dépend de la topologie du maillage. Afin de traiter ces cas efficacement, un système complexe est mis en place par la {\tt GMlib}. Tout d'abord la commande de renumérotation de Hilbert, nécessaire pour obtenir de bonnes performances d'accès mémoire, propose un mode spécifique au GPU et va ordonner les sommets du maillage selon leur degré croissant. Ainsi, tous les premiers sommets ayant un degré inférieur ou égal à 8 auront leur boule de triangle stockée dans un vecteur de cette taille (avec d'éventuelles valeurs nulles), puis les boules des sommets suivants seront stockées sur des vecteurs de taille 16 et ainsi de suite. Tout ceci est transparent pour l'utilisateur qui pourra connaitre le degré du sommet en cours avec la variable automatique {\tt VerTriDeg}, (Vertex' triangles degree).
Remarque : une variable accédée indirectement via un lien montant pourra être nulle du fait que les vecteurs sont alignés sur des puissances de deux et que le degré réel peut être inférieur.
Pour rester dans la même thématique, nous allons cette fois-ci boucler sur les sommets, accéder aux barycentres des triangles de la boule, et relaxer les coordonnées du sommet vers la moyenne des barycentres, pourquoi pas ?



\subsection{Paire de Kernels scatter / gather}

\subsection{Programmation en OpenCL}


%
%  2 / UTILISATION
%

\section{Utilisation}

\subsection{Installation et compilation}

\subsection{Initialisation}

\subsection{Exemple 1 : calcul d'une valeur moyenne pour chaque triangle d'un maillage}

\subsection{Exemple 2 : boucle à accès mémoire indirect présentant des dépendances mémoires}


%
%  3 / COMMANDES
%

\section{Liste des commandes}

\subsection{GmlCheckFP64}

Permets de tester la présence ou non d'unités de calcul flottant en double précision.
La norme OpenCL rend obligatoire la présence d'unités 32-bits, mais les capacités 16-bits (demi-précision) et 64-bits sont optionnelles.

\subsubsection*{Syntaxe}
{\tt flag = GmlCheckFP64(LibIdx);}
\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
flag       & int    & 0 : pas de capacité de calcul flottant 64-bit, 1 : FP64 disponible \\
\hline
\end{tabular}
\subsubsection*{Commentaires}
Bien que des unités de calculs double précision soient présentent sur la plupart des GPU de jeux vidéos, leur nombre est vouent 1/4 à 1/32 du nombre d'unités 32-bits, réduisant d'autant la vitesse de calcul.
Cette dernière est alors inférieure à celle du CPU principal !
La capacité FP64 du GPU est alors un faux ami.

\subsection{GmlCompileKernel}

\subsection{GmlDebugOff}

Désactive le mode de débogage (qui désactivé par défaut).

\subsubsection*{Syntaxe}

{\tt GmlDebugOff(LibIdx);}
\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}
\subsubsection*{Commentaires}


\subsection{GmlDebugOn}

Active le mode de débogage qui permet d'afficher l'intégralité des sources compilés avec notamment les parties de lectures et écriture mémoire ajoutées par la librairie.

\subsubsection*{Syntaxe}

{\tt GmlDebugOn(LibIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
 & & \\
\hline
\end{tabular}

\subsubsection*{Commentaires}


\subsection{GmlExtractEdges}
Non implémenté.

\subsubsection*{Syntaxe}

{\tt DatIdx = GmlExtractEdges(LibIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
DatIdx     & int    & \\
\hline
\end{tabular}

\subsubsection*{Commentaires}


\subsection{GmlExtractFaces}
Non implémenté.

\subsubsection*{Syntaxe}

{\tt DatIdx = GmlExtractFaces(LibIdx);}

\subsubsection*{paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
DatIdx     & int    & \\
\hline
\end{tabular}

\subsubsection*{Commentaires}


\subsection{GmlFreeData}

\subsubsection*{Syntaxe}

Libère la mémoire occupée sur le CPU et le GPU par cette donnée.

{\tt flag = GmlFreeData(LibIdx, DatIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
DatIdx     & int     & \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
flag       & int    & \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
L'étiquette sera réutilisée par de futures créations de données, donc faire attention à ne pas confondre l'ancienne et la nouvelle dans ses listes de types.


\subsection{GmlGetDataLine}

Permets de récupérer les données du GPU et de les stocker dans les variables de l'utilisateur.
Cette procédure concerne tous les types de données, maillage, solutions et liens topologiques.
Le nombre d'arguments est variable et l'utilisateur doit fournir un pointeur de type adéquat pour chaque scalaire composant une ligne de ce type.

\subsubsection*{Syntaxe}

{\tt flag = GmlGetDataLine(LibIdx, DatIdx, LinNmb, ...);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type            & description \\
\hline
LibIdx     & size\_t         & l'index de l'instance tel que retourné par GmlInit() \\
\hline
DatIdx     & int             & index de la donnée à renseigner \\
\hline
LinNmb     & int             & numéro de la ligne dans cette donnée \\
\hline
...        & int * / float * & pointeur sur un entier ou un flottant qui \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
flag       & int    & 0 : échec, 1 : succès \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Après l'exécution d'un kernel sur le GPU, les données indiquées comme GMLWriteMode ne sont pas immédiatement transférées du GPU vers le CPU.
C'est l'appel à GmlGetDataLine() de la première ligne de donnée qui déclenche le transfert en bloc de la totalité des lignes du champ.
Il en découle que si vous commencez par lire les données sans commencer par la première ligne, les données retournées seront vides.


\subsection{GmlGetMemoryTransfer}

\subsubsection*{Syntaxe}

Permet de connaitre à tout instant la quantité de mémoire en octets transférée de ou vers le GPU.

{\tt taille = GmlGetMemoryUsage(LibIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type    & description \\
\hline
taille     & size\_t & \\
\hline
\end{tabular}


\subsection{GmlGetMemoryUsage}

Permets de connaitre la quantité de mémoire en octets actuellement utilisée par la {\tt GMlib} sur le GPU.

\subsubsection*{Syntaxe}

{\tt taille = GmlGetMemoryUsage(LibIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type    & description \\
\hline
taille     & size\_t & \\
\hline
\end{tabular}


\subsection{GmlImportMesh}

Cette routine est une aide (\emph{helper}) qui permet en une seule commande de lire un maillage, d'initialiser les types de données qu'il contient sur le GPU et de les transférer.
Elle n'est présente dans la {\tt GMlib} qui si elle a été compilée avec le flag {\tt -DWITH\_LIBMESHB}.
L'idée est de donner un nom de fichier mesh et la liste des mots clefs que vous souhaitez importer, s'ils sont présents dans le fichier.
La procédure retourne simplement le nombre de ces mots-clefs trouvés.
Afin d'en connaitre les index pour les manipuler par la suite, il fait appeler pour chacun d'eux la commande GetMeshInfo().

\subsubsection*{Syntaxe}

{\tt NmbKwd = GmlImportMesh(LibIdx, FilNam, ...);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
FilNam     & char *  & chemin d'accès complet et noms du fichier avec son extension \\
\hline
...        & int     & liste des mots-clefs de maillages ou solution tels que définis par la {\tt libMeshb} \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
NmbKwd     & int    & nombre de mots-clefs effectivement trouvés et lus \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Attention à passer en arguments les étiquettes de mots-clefs définis par la {\tt libMeshb} et non par la {\tt GMlib} !


\subsection{GmlInit}

Permets d'initialiser une instance de la librairie avec une unité de calcul capable d'exécuter du code OpenCL.
La liste de ces unités est disponible via la commande \emph{GmlListGPU}.
Notez qu'il est possible d'ouvrir plusieurs instances de la {\tt GMlib} afin de bénéficier de la capacité de calcul des différentes unités et même d'ouvrir plusieurs instances sur la même unité, dont le temps machine sera alors partagé.

\subsubsection*{Syntaxe}

{\tt LibIdx = GmlInit(DevIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type   & description \\
\hline
DevIdx     & int    & numéro de l'unité de calcul sur laquelle exécuter tous les kernels de cette instance \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type    & description \\
\hline
LibIdx     & size\_t & identifiant unique de l'instance de la librairie \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Par défaut, les systèmes rangent les unités de type CPU en premier et les GPU en dernier.
De fait, l'unité 0 étant presque toujours un CPU, il est pertinent d'exécuter un {\tt GmlInit(0)} par défaut en l'absence d'indication de la part de l'utilisateur. Un tel choix est garanti de fonctionner sur tout système.


\subsection{GmlLaunchKernel}

Lancement de l'exécution d'un kernel déjà compilé.
Cette procédure prend très peu de paramètres, car tout a été défini au moment de la compilation : nombre d'itération de la boucle, les données à lire ou écrire, code à compiler ainsi que le GPU ou CPU exécutant.
Il ne reste alors qu'à donner un index d'instance de librairie et un numéro de kernel et ça démarre !
La procédure est bloquante et ne rends la main qu'a la fin de l'exécution, mais cette une limitation imposée par la version actuelle de la {\tt GMlib} qui sera levée par la suite afin de permettre des exécutions en \emph{pipeline}.

\subsubsection*{Syntaxe}

{\tt temps = GmlLaunchKernel(LibIdx, KrnIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
KrnIdx     & int     & numéro du kernel à exécuter \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
temps      & double & si < 0 : code d'erreur, si >=0 : temps d'exécution en secondes \\
\hline
\end{tabular}


\subsection{GmlListGPU}

Cette procédure se contente d'afficher à l'écran les noms complets des unités de calculs compatibles OpenCL sur le système.
En cas de lancement d'un logiciel en ligne de commande sans entrer d'unité de calcul GPU, il est utile d'appeler {\tt GmlListGPU()} comme message d'aide par défaut.

\subsubsection*{Syntaxe}

{\tt GmlListGPU();}

\subsubsection*{Commentaires}
Les systèmes rangent en général des unités de type CPU dans les premiers indices et les GPU en dernier.


\subsection{GetMeshInfo}

Permets de retrouver le numéro de datatype et le nombre de lignes à partir du simple type de donnée de maillage.
Cela est utile après l'appel de {\tt GmlImportMesh} afin de connaitre les informations sur tous les mots-clefs importés du fichier de maillage ou solutions.

\subsubsection*{Syntaxe}

{\tt flag = GetMeshInfo(LibIdx, MshTyp, NmbLin, DatIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
MshTyp     & int     &  \\
\hline
NmbLin     & int     &  \\
\hline
DatIdx     & int *   &  \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
flag       & int    & \\
\hline
\end{tabular}

\subsubsection*{Commentaires}

Si un des pointeurs NmbLin ou DatIdx est nul, il ne sera tout simplement pas renseigné.


\subsection{GmlNewLinkData}

Cette commande permet de créer des liens topologiques arbitraires entre deux types de données de maillage.
Elle fonctionne de la même manière que les autres créations de données, {\tt GmlNewMeshData} et {\tt GmlNewSolutionData}, à savoir qu'on en précise le nombre de champs (des entiers) et qu'on boucle sur chaque ligne pour les renseigner.
Mais c'est un outil extrêmement puissant, car il permet de contourner les limitations d'accès mémoire indirectes des GPU en passant par des tables d'indirection astucieusement conçues.

\subsubsection*{Syntaxe}

{\tt DatIdx = GmlNewLinkData(LibIdx, MshTyp, LnkTyp, NmbDat, LnkNam);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
MshTyp     & int     & étiquette de l'entité de maillage source \\
\hline
LnkTyp     & int     & étiquette de l'entité de maillage qui est pointée par la source \\
\hline
NmbDat     & int     & nombre d'entités de type LnkTyp pointées par chaque entité de type MshTyp \\
\hline
LnkNam     & char *  & nom donné au tableau contenant le lien tel qu'il sera transmis au code OpenCL  \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
DatIdx     & int    & étiquette de la donnée résultante \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Ce lien topologique arbitraire est destiné à se substituer au lien par défaut généré automatiquement par la librairie.
Il faut alors en passer l'étiquette à la place de la valeur 0 par défaut pour chaque type de donné concerné dans l'appel de compilation d'un kernel.


\subsection{GmlNewMeshData}

Création d'un type de donné de maillage, pour le moment seul l'ordre un, mais mixte est proposé.
Le type {\tt GmlVertices} est composé des coordonnées et d'une référence et tous les autres éléments sont composés des numéros de leurs sommets et d'une référence.
Notez qu'il ne peut y avoir qu'un seul tableau d'un type d'entité par instance de la librairie.
Cette limitation à un maillage par instance sera levée dans les prochaines versions.

\subsubsection*{Syntaxe}

{\tt DatIdx = GmlNewMeshData(LibIdx, MshTyp, NmbLin);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
MshTyp     & int     & type d'entité de maillage tel que défini dans le header \\
\hline
NmbLin     & int     & nombre de ligne de ce tableau d'entités \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
DatIdx     & int    & étiquette du datatype alloué et à passer en argument aux autres routines \\
\hline
\end{tabular}


\subsection{GmlNewParameters}

Permets d'allouer une structure librement définie par l'utilisateur et contenant toute sorte de paramètres nécessaires à la communication entre le CPU et le GPU.
Une image miroir du côté CPU et du côté GPU sera automatiquement synchronisée, avant chaque exécution de kernel, la structure sera recopiée de la mémoire CPU vers le GPU afin qu'il puisse y lire des paramètres et à la fin, la copie en mémoire GPU sera rapatriée sur le CPU afin d'y lire d'éventuels résultats de calculs ou codes d'erreurs.

\subsubsection*{Syntaxe}

{\tt ParDat = GmlNewParameters(LibIdx, taille, source);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
taille     & int     & c'est le sizeof(my\_struct) en octets \\
\hline
source     & char *  & source du code contenant la définition de la structure afin de la rendre visible côté OpenCL \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
ParDat     & void * & pointeur sur la structure allouée en mémoire CPU \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Afin de garantir que la structure est identique du côté CPU et GPU, il est habile d'inclure sa définition dans un header coté CPU et de passer ce header comme code OpenCL à compiler via la commande {\tt GmlNewParameters}.
Bien que la taille de la structure ne soit pas limitée, comme elle sera transférée deux fois à chaque lancement de kernel (upload / download), cela pénalisera le temps d'exécution si elle est utilisée pour transférer de gros tableaux.
Ceci est en revanche très utile pour déboguer un code en recopiant la totalité d'un tableau problématique dans la structure afin de l'analyser du côté CPU.


\subsection{GmlNewSolutionData}

Création d'un type de donné libre associé à une entité de maillage.
Bien qu'il y ait "solution" dans le nom, ce type est fait pour y stocker ce que l'on veut.
On choisi le type OpenCL (entier, flottant, scalaire, vecteur) et la taille du tableau local, attention, il s'agit du nombre de variables associé à chaque entité de maillage, pas du nombre total de lignes de ce champ qui est par définition égal au nombre de lignes de l'entité de maillage auquel il fait référence.
Il n'est pas possible de stocker des types différents, à la manière d'une structure en C, mais seulement un tableau homogène. Si vous avez besoin de mélanger des deux entiers et des quatre flottants associés à chaque triangle par exemple, il est tout à fait possible d'allouer deux {\tt SolutionData} associées aux triangles, l'une composé d'un {\tt GmlInt2} et l'autre d'un {\\ GmlFloat4}. Notez qu'il est possible de demander un tableau de {\tt 2 x GmlInt} et un autre de {\\ 4 x GmlFloat}, ce qui revient au même.

\subsubsection*{Syntaxe}

{\tt DatIdx = GmlNewSolutionData(LibIdx, MshTyp, NmbDat, ItmTyp, DatNam);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
MshTyp     & int     & étiquette du type de maillage auquel ce champ est associé \\
\hline
NmbDat     & int     & taille du tableau local \\
\hline
ItmTyp     & int     & type de chaque entrée du tableau tel que défini dans le header \\
\hline
DatNam     & char *  & nom du champ tel qu'il apparaitra du côté OpenCL \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
DatIdx     & int    & étiquette du datatype à passer aux autres routines \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Seuls les entiers (8 et 32 bits) et les flottants (32 et 64 bits) sont disponibles pour le moment.
Tout type est disponible sous la forme d'un scalaire ou d'un vecteur de puissance 2 allant jusqu'à 16.


\subsection{GmlReduceVector}

Réduction d'un vecteur de flottant à une seule valeur scalaire (norme).
Le format d'entrée est imposé, il s'agit d'un tableau contenant un seul scalaire flottant simple précision par ligne.
Les normes de vecteur sont pré codées et il n'est pas possible de définir les siennes pour l'instant, mais il sera possible ultérieurement de proposer des kernels de réduction.
Afin de contourner ces limitations, il faut passer par un kernel intermédiaire qui va réaliser le calcul souhaiter et en stocker le résultat dans un tableau de flottant qui sera réduit par {\tt GmlReduceVector}.
Les opérations proposées sont la somme des termes, la valeur minimum et la maximum.

\subsubsection*{Syntaxe}

{\tt temps = GmlReduceVector(LibIdx, DatIdx, OppCod, norme);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type     & description \\
\hline
LibIdx     & size\_t  & l'index de l'instance tel que retourné par GmlInit() \\
\hline
DatIdx     & int      & étiquette du datatype contentant le vecteur à réduire  \\
\hline
OppCod     & int      & code de l'opération de réduction à effectuer telle que défini dans le header \\
\hline
norme      & double * & valeur résiduelle \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
temps      & double & temps d'exécution en secondes \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Les codes OpenCL des trois opérations proposées se trouvent dans le fichier reduce.cl et il est très simple de s'en inspirer afin d'y ajouter son propre calcul de norme.


\subsection{GmlSetDataBlock}

Cette procédure est similaire à {\tt GmlSetDataLine} mais transfert la totalité des lignes d'un datatype d'un seul coup au lieu d'une ligne à la fois. Cela permet d'une part de meilleures performances, mais aussi d'écrire des routines de transfert génériques à tous types de données étant donné que les paramètres ne font appel qu'à des pointeurs en mémoire et non aux valeurs, forcément différente, contenue dans chaque type de donnée.
On indique donc, le numéro de la ligne de départ, celle de fin, et les pointeurs sur les données utilisateur de la première ligne et de la dernière à transférer.

\subsubsection*{Syntaxe}

{\tt flag = GmlSetDataBlock(LibIdx, TypIdx, BegIdx, EndIdx, DatBeg, DatEnd, RefBeg, RefEnd);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
TypIdx     & int     & étiquette du datatype à renseigner \\
\hline
BegIdx     & int     & numéro de la première ligne à envoyer \\
\hline
EndIdx     & int     & numéro de la dernière ligne  \\
\hline
DatBeg     & void *  & pointeur sur les données utilisateur de la première ligne \\
\hline
DatEnd     & void *  & idem sur la dernière \\
\hline
RefBeg     & int *   & pointeur sur la référence associé à la première ligne ou NULL s'il ne s'agit pas d'un type de donnée de maillage (solution) \\
\hline
RefEnd     & int *   & pointeur sur la dernière référence \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
flag       & int    & 0 : échec, 1 : succès \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
La procédure est pour l'instant bloquante, mais elle sera lancée en parallèle dans un thread à l'avenir afin de réaliser les initialisations de données en pipeline.
De plus, il est prévu que la routine {\tt GmlImportMesh} utilise {\tt GmfReadBlock} et {\tt GmlSetDataBlock} en pipeline afin de lire, préparer et transférer les données en même temps.



\subsection{GmlSetDataLine}

Renseigne une ligne d'un type de donné, de maillage ou autre, afin que la librairie puisse la stocker sur CPU et GPU.
Le nombre d'arguments dépend bien évidemment du type de la donnée.
Cette routine permet de renseigner les données de maillage, de solutions ou bien des liens arbitraires entre types.
Le nombre d'arguments et leur type est variable et correspond à la définition de l'entité de maillage ou du lien topologique tel que défini par l'utilisateur.
Attention, dans le cas des données de solution, on passe un seul et unique pointeur vers la table les contenant de manière consécutive en mémoire, ceci afin de rendre génériques les routines de transfert, car la nature et la taille de ces champs varient selon le contexte du solveur.

\subsubsection*{Syntaxe}

{\tt flag = GmlSetDataLine(LibIdx, DatIdx, LinNmb, ...);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type      & description \\
\hline
LibIdx     & size\_t   & l'index de l'instance tel que retourné par GmlInit() \\
\hline
DatIdx     & int       & étiquette du datatype à renseigner \\
\hline
LinNmb     & int       & numéro de la ligne à renseigner \\
\hline
...        & int/float & liste variable d'arguments contenant les données de ce type de maillage ou de lien topologique ou bien un pointeur sur le tableau contenant la solution associée \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
flag       & int    & 0 : échec, 1 : succès \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Faire très attention aux paramètres de la section variable, car le compilateur C n'a aucun moyen d'en vérifier le nombre et le type requis.


\subsection{GmlSetNeighbours}

Création d'une donnée de type lien topologique et contenant la liste des voisins entre entités du même type.
Deux entités de dimension D sont dites voisines si elles partagent une même entité géométrique de dimension D-1 (par exemple deux tétraèdres sont voisins s'ils partagent un triangle).
Cette liste pourrait tout à fait être créée manuellement par l'utilisateur avec un appel à {\tt GmlNewLinkData} puis en créant lui-même le tableau des voisinages et en la renseignant avec {\tt GmlSetDataBlock}.
La procédure {\tt GmlSetNeighbours} est proposée comme \emph{helper} afin d'en faciliter la tâche et de réduire la taille des codes.

\subsubsection*{Syntaxe}

{\tt DatIdx = GmlSetNeighbours(LibIdx, EleIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
EleIdx     & int     & étiquette du type de donnée de maillage dont on veut construire les voisins \\
\hline
\end{tabular}

\medskip

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Retour     & type   & description \\
\hline
DatIdx     & int    & étiquette sur une donnée de type lien topologique \\
\hline
\end{tabular}

\subsubsection*{Commentaires}
Le lien topologique ainsi créé pourra être fourni à la compilation d'un kernel à la place du lien par défaut (valeur 0 du paramètre).


\subsection{GmlStop}

Libère tous les contextes et structure OpenCL, la mémoire sur le CPU et le GPU, et termine l'instance, mais pas la librairie qui peut continuer à fonctionner avec les éventuelles autres instances allouées.

\subsubsection*{Syntaxe}

{\tt GmlStop(LibIdx);}

\subsubsection*{Paramètres}

\begin{tabular}{|m{2cm}|m{1.5cm}|m{10.5cm}|}
\hline
Paramètre  & type    & description \\
\hline
LibIdx     & size\_t & l'index de l'instance tel que retourné par GmlInit() \\
\hline
\end{tabular}


%
%  4 / GLOSSAIRE
%


\section{Glossaire}

\subsection{API}
Application programming interface, ou interface de programmation, c'est la liste des arguments et leur format à fournir afin d'appeler une procédure d'un programme ou librairie.

\subsection{Compute Unit}
Une puce GPU contient un grand nombre d'unités de calcul fonctionnant en parallèle de la même manière qu'un CPU possède plusieurs c\oe urs. Les constructeurs jouent un peu sur les mots en comptant chaque unité vectorielle capable de traiter quatre scalaires à la fois comme étant quatre unités de calculs distinctes, ce qui n'est en pratique pas tout à fait le cas. À ce compte, un CPU comme l'Intel core i7-3770 qui possède quatre c\oe urs, chacun possédant une unité vectorielle capable de traiter huit flottants simultanément, serait considéré comme une puce à 32 unités de calculs selon cette terminologie.

Il est à noter que les unités de GPU sont beaucoup plus simples que celles des CPU et leur puissance de calcul par gigahertz est typiquement trois fois plus faible. Une comparaison du nombre de c\oe urs-gigahertz entre les deux architectures n'est pas non plus réaliste.

\subsection{GPU}
Graphic Processing Unit, aussi appelé GPGPU (pour General Purpose), c'est une puce adaptée aux calculs géométriques et vectoriels qui, comme son nom ne l'indique pas, est tout sauf "general purpose" !
Ces puces se trouvent dans les cartes graphiques des deux constructeurs bien connus, AMD-ATI Radeon et NVIDIA GeForce, mais il y aussi des GPU dans la plupart de puces pour smartphones et tablettes (ARM Mali et Imagination Technologies SGX) et les consoles des jeux (IBM Cell).

\subsection{Kernel}
Nom donné à une boucle exécutée par un GPU. Celui-ci gère lui-même l'indice de boucle qu'il distribue à ses unités de calculs, l'utilisateur ne fournissant que le noyau de calcul à l'intérieur de la boucle, d'où le nom kernel.

\subsection{OpenCL}
Open Compute Langage, c'est un langage dérivé du C, avec quelques emprunts au C++, et qui a été conçu pour être indépendant de toute architecture matérielle. Il peut donc être exécuté efficacement sur des GPU, des CPU multic\oe urs, des FPGA ou tout type de matériel calculant de manière concurrente. Son objectif est d'exposer clairement l'indépendance entre les calculs afin de mieux les répartir sur les différentes unités.

\subsection{Workgroup}
C'est une portion de boucle qui est exécutée simultanément sur les différentes unités de calculs du GPU. C'est pourquoi on ne peut jamais supposer que l'itération $i$ d'une boucle sera exécutée avant l'itération $i+1$, car elles peuvent tout à fait être traitées en même temps par deux unités différentes. Ces tailles vont de 16 pour les smartphones jusqu'à 1024 pour les cartes dédiées au calcul GPU.


%
% BIBLIO
%

\addcontentsline{toc}{section}{Bibliographie}

\begin{thebibliography}{99}
\small

\bibitem{peano_hilbert}
	SAGAN,
	Space-Filling Curves,
	\emph{Springer Verlag, New York, 1994}.

\bibitem{khronos}
	Aaftab Munshi,
	The OpenCL Specification,
	\emph{Khronos Group, http://www.khronos.org/opencl/, 2012}.

\bibitem{nvidia}
	NVIDIA Corporation,
	OpenCL Optimization,
	\emph{NVIDIA Corporation, NVIDIA\_GPU\_Computing\_Webinars\_Best\_Practises\_For\_OpenCL\_Programming.pdf, 2009}.

\bibitem{lohner}
	Andrew Corrigan \& Rainald Löhner,
	Porting of FEFLO to Multi-GPU Clusters,
	\emph{49th AIAA Aerospace Sciences Meeting, Orlando, January 2011}.

\bibitem{apple}
	Apple Corp,
	OpenCL Programming Guide for Mac,
	\emph{http://developer.apple.com, 2012}.



\end{thebibliography}

\end{document}
